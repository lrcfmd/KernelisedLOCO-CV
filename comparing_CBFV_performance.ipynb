{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "013523af-d9ad-4a60-b3b3-b358b5d9252e",
   "metadata": {},
   "source": [
    "## Evaluating performance of composition based feature vectors\n",
    "\n",
    "This file will take you through an example of comparing two different featurisation methods 'fractional' (refered to here as onehot for legacy reasons) and 'magpie' with eachother. \n",
    "\n",
    "We'll use 80/20 train/test splits, then LOCO-CV and Kernelised LOCO-CV\n",
    "\n",
    "Then we'll compare to random projections of the same size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07461fdf-8441-406e-a789-05f979275822",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First some imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf269cf-5497-4887-a988-3a8b8ab5d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "import json\n",
    "from utilities import do_loco_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba74575d-fc04-45c9-aea7-7d2cd0f29791",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/case_studies'\n",
    "task_info = 'task_info.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5600f60-661c-462e-ab7a-80e0be9de234",
   "metadata": {},
   "source": [
    "### For ease we've put information about the different tasks into a large dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "979a6cb9-e983-47f6-9326-90c78102fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(task_info) as f:\n",
    "    tasks = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1b1e4a-7067-490c-b5ad-f920779ab1f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now lets set up our experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8283cc5c-0a49-46f7-b392-4f4a5db2cba0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "our options for featurisation are as follows:\n",
    "* 'oliynyk': Oliynyk Originally designed for prediction of Heusler structured intermetallics 13 , the Oliynyik feature set as implemented in previous work includes 44 features 5. For each of these, the weighted mean, sum, range, and variance of that feature amongst the constituent elements of the compound are taken. Features include atomic weight, metal, metalloid or non metallic properties, periodic table based properties (Period, group, atomic number), various measures of radii (atomic, Miracle, covalent), electronegativity, valency features (such as the number of s, p, d, and f valence electrons), and thermal features (such as boiling point and specific heat capacity).\n",
    "* 'jarvis' : JARVIS combines structural descriptors with chemical descriptors to create “classical force-field inspired descriptors” (CFID). Structural descriptors include bond angle distributions neighbouring atomic sites, dihedral atom distributions, and radial distributions, among others. Chemical descriptors used include atomic mass, and mean charge distributions. Original work generated CFIDs for tens of thousands of DFT-calculated crystal structures 14 , and subsequent work adapted CFIDs for individual elements to be used in CBFVs for arbitrary compositions without known structures.\n",
    "* 'magpie' : While the Materials-Agnostic Platform for Informatics and Exploration (MAGPIE) is the name of a library associated with Ward et al.’s work, it this has become synonymous with the 115 features used in the paper and as such we will use Magpie refer to the feature set. These features include 6 stoichiometric attributes which are different normalistion methods (L P norms) of the elements present. These capture information of the ratios of the elements in a material without taking into account what the elements are, 115 elemental based attributes are used, which are derived from the minimum, maximum, range, standard deviation, mode (property of the most prevalent element) and weighted average of 23 elemental properties including atomic number, Mendeleev number, atomic weight among others. Remaining features are derived from valence orbital occupation, and ionic compound attributes (which are based on differences between electronegativity between constituent elements in a compound).\n",
    "* 'random_200' : A random vector featurisation used by Murdock et al. to represent a lower bounds for performance.\n",
    "* 'onehot' : (referred to as fractional in the paper, but onehot in code for legacy reasons). This is an implementation of a one-hot style encoding of composition which includes average, sum, range, and variance of each element.\n",
    "* 'compVec' : a one-hot style encoding of composition as used in ElemNet (containing only the proportions of each element in a composition). Differences between this and fractional are further discussed in section 2.1 of the associated paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92741be1-ea6d-4585-a239-a5803db78594",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'GFA'\n",
    "featurisations = ['magpie','onehot'] # For legacy reasons we refer to onehot in the paper as fractional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fca7ae9b-52b8-415d-8d41-2f79405161f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = accuracy_score if tasks[task]['type'] == 'classification' else r2_score\n",
    "model = RandomForestClassifier() if tasks[task]['type'] == 'classification' else RandomForestRegressor() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ad65e3-f79e-4630-88eb-e0000e01b06a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First lets look at scores with an 80/20 train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8a18954-ed52-437f-a9ad-044aadfc0547",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfv_train_test_score = {} #We will later compare these to random projections, and to LOCO-CV scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a6bb70a-0623-43d8-822f-72e09b90f013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for magpie is 0.568\n",
      "Score for onehot is 0.543\n"
     ]
    }
   ],
   "source": [
    "for featurisation_method in featurisations:\n",
    "    #Find files\n",
    "    task_folder = os.path.join(data_folder, #were the data is\n",
    "                 'CBFV_data', #whether we are investigating CBFVs or random projections\n",
    "                 tasks[task]['study_folder'], #Which study?\n",
    "                 '80_20_split',#80_20_split or LOCO-CV?\n",
    "                 tasks[task]['type'], #regression or classification?\n",
    "                 tasks[task]['task_folder']) #Which task?\n",
    "    train_file = os.path.join(task_folder, f'{featurisation_method}_train_CBFV.csv')\n",
    "    test_file = os.path.join(task_folder, f'{featurisation_method}_test_CBFV.csv')\n",
    "    \n",
    "    #Load in files\n",
    "    train_df = pd.read_csv(train_file)\n",
    "    test_df = pd.read_csv(test_file)\n",
    "    \n",
    "    #Train model\n",
    "    train_x = train_df.drop(['target','formula'], axis=1)\n",
    "    train_y = train_df['target']\n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    #Make predictions on test set\n",
    "    test_x = test_df.drop(['target','formula'], axis=1)\n",
    "    test_y = test_df['target']\n",
    "    predictions = model.predict(test_x)\n",
    "    \n",
    "    #Measure performance\n",
    "    score = metric(test_y, predictions)\n",
    "    print(f'Score for {featurisation_method} is {round(score,3)}')\n",
    "    cbfv_train_test_score[featurisation_method] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34575284-10eb-4df4-a8f0-8850f1486f52",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now LOCO-CV and kernelised LOCO-CV\n",
    "We see that when it comes to measuring LOCO-CV and kernelised LOCO-CV are used in exactly the same way. The difference is in how the data are clustered. For reproducibility here we use the same clusters that are reported in the paper, for an example on how to implement kernelised LOCO-CV please see preparing_kernelised_LOCO_CV.ipynb\n",
    "We have defined a function do go through the LOCO-CV. From the source code we can see it is quite simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f6fb224-dc6b-4289-b726-37760396b3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m  \u001b[0mdo_loco_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_score_breakdown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mdo_loco_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_score_breakdown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Performs LOCO-CV given predefined clusters.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        clusters (list): Clusters with which to apply LOCO-CV\u001b[0m\n",
       "\u001b[0;34m            in the form [{'k':2, 'formulae':['H2O','NaCl'....],'clusters':[0,1...]},{'k':2...]\u001b[0m\n",
       "\u001b[0;34m        data (pandas.DataFrame): data to apply LOCO-CV to.\u001b[0m\n",
       "\u001b[0;34m        model (any model that uses SKlearn style .fit, .predict interface): the model to evaluate.\u001b[0m\n",
       "\u001b[0;34m        metric (function that takes in true and predicted values): metric to evaluate model with.\u001b[0m\n",
       "\u001b[0;34m        return_score_breakdown (bool): whether to return per cluster scores as well\u001b[0m\n",
       "\u001b[0;34m         as the overall mean score of the model.\u001b[0m\n",
       "\u001b[0;34m    Returns:\u001b[0m\n",
       "\u001b[0;34m       float or list if return_score_breakdown: the performance of the model\u001b[0m\n",
       "\u001b[0;34m           (and the associated per cluster scores if return_score_breakdown).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m   \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mall_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m#For each value of k\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mclustering\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclustering_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m#For each cluster\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m#Train the model\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'formula'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m#Make predictions on test set\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'formula'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mclustering_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mall_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mper_clustering_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moverall_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_clustering_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_clustering_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mreturn_score_breakdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0moverall_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_clustering_means\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0moverall_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/work/KernelisedLOCO-CV/utilities.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?? do_loco_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f6854b-01a9-4f69-a29b-2b9672fbc7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfv_loco_cv_score = {}\n",
    "cbfv_kernelised_loco_cv_score = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c2cb52-b47b-4bef-be93-a585c3dd67f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCO-CV score for magpie is 0.64\n",
      "kernelised LOCO-CV score for magpie is 0.876\n",
      "LOCO-CV score for onehot is 0.586\n",
      "kernelised LOCO-CV score for onehot is 0.743\n"
     ]
    }
   ],
   "source": [
    "##This takes a while to run\n",
    "for featurisation_method in featurisations:\n",
    "    #Find files\n",
    "    task_folder = os.path.join(data_folder, #were the data is\n",
    "                 'CBFV_data', #whether we are investigating CBFVs or random projections\n",
    "                 tasks[task]['study_folder'], #Which study?\n",
    "                 'LOCO-CV',#80_20_split or LOCO-CV?\n",
    "                 tasks[task]['type'], #regression or classification?\n",
    "                 tasks[task]['task_folder']) #Which task?\n",
    "    data_file = os.path.join(task_folder,f'{featurisation_method}_CBFV.csv')\n",
    "    loco_cv_split_file = os.path.join(task_folder,f'{featurisation_method}_CBFV.json')\n",
    "    kernelised_loco_cv_split_file = os.path.join(task_folder,f'{featurisation_method}_CBFV_rbf.json')\n",
    "    \n",
    "    data = pd.read_csv(data_file)\n",
    "    if tasks[task]['type'] == 'classification':\n",
    "        data['target'] = data['target'].astype(int)\n",
    "    with open(loco_cv_split_file) as f:\n",
    "        loco_cv_split = json.load(f)\n",
    "    with open(kernelised_loco_cv_split_file) as f:\n",
    "        kernelised_loco_cv_split = json.load(f)\n",
    "    \n",
    "    loco_cv_score = do_loco_cv(loco_cv_split, data, model, metric)\n",
    "    print(f'LOCO-CV score for {featurisation_method} is {round(loco_cv_score,3)}')\n",
    "    cbfv_loco_cv_score[featurisation_method] = loco_cv_score\n",
    "    \n",
    "    kernelised_loco_cv_score = do_loco_cv(kernelised_loco_cv_split, data, model, metric)\n",
    "    print(f'kernelised LOCO-CV score for {featurisation_method} is {round(kernelised_loco_cv_score,3)}')\n",
    "    cbfv_kernelised_loco_cv_score[featurisation_method] = kernelised_loco_cv_score\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9915d734-7e18-4683-848a-110c94f19408",
   "metadata": {},
   "source": [
    "## Lets compare this to random projections of the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa8950b0-e310-49c5-a917-c2f18c5a70e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_projection_train_test_score = {} #We will later compare these to random projections, and to LOCO-CV scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35dd4aeb-3360-48e5-add7-ac575ff21eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for magpie is 0.87\n",
      "Score for onehot is 0.875\n"
     ]
    }
   ],
   "source": [
    "for featurisation_method in featurisations:\n",
    "    #Find files\n",
    "    task_folder = os.path.join(data_folder, #were the data is\n",
    "                 'random_projection_data', #whether we are investigating CBFVs or random projections\n",
    "                 tasks[task]['study_folder'], #Which study?\n",
    "                 '80_20_split',#80_20_split or LOCO-CV?\n",
    "                 tasks[task]['type'], #regression or classification?\n",
    "                 tasks[task]['task_folder']) #Which task?\n",
    "    train_file = os.path.join(task_folder, f'{featurisation_method}_train_projection.csv')\n",
    "    test_file = os.path.join(task_folder, f'{featurisation_method}_test_projection.csv')\n",
    "    #Load in files\n",
    "    train_df = pd.read_csv(train_file)\n",
    "    test_df = pd.read_csv(test_file)\n",
    "    \n",
    "    #Train model\n",
    "    train_x = train_df.drop(['target','formula'], axis=1)\n",
    "    train_y = train_df['target']\n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    #Make predictions on test set\n",
    "    test_x = test_df.drop(['target','formula'], axis=1)\n",
    "    test_y = test_df['target']\n",
    "    predictions = model.predict(test_x)\n",
    "    \n",
    "    #Measure performance\n",
    "    score = metric(test_y, predictions)\n",
    "    print(f'Score for {featurisation_method} is {round(score,3)}')\n",
    "    random_projection_train_test_score[featurisation_method] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5ce20b2-0ace-402d-a7d8-fad6e43380d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_projection_loco_cv_score = {}\n",
    "random_projection_kernelised_loco_cv_score = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "012df1e3-d62a-46ed-be9c-6650e8ce8298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCO-CV score for magpie is 0.628\n",
      "kernelised LOCO-CV score for magpie is 0.876\n",
      "LOCO-CV score for onehot is 0.592\n",
      "kernelised LOCO-CV score for onehot is 0.742\n"
     ]
    }
   ],
   "source": [
    "##This takes a while to run\n",
    "for featurisation_method in featurisations:\n",
    "    #Find files\n",
    "    task_folder = os.path.join(data_folder, #were the data is\n",
    "                 'CBFV_data', #whether we are investigating CBFVs or random projections\n",
    "                 tasks[task]['study_folder'], #Which study?\n",
    "                 'LOCO-CV',#80_20_split or LOCO-CV?\n",
    "                 tasks[task]['type'], #regression or classification?\n",
    "                 tasks[task]['task_folder']) #Which task?\n",
    "    data_file = os.path.join(task_folder,f'{featurisation_method}_CBFV.csv')\n",
    "    loco_cv_split_file = os.path.join(task_folder,f'{featurisation_method}_CBFV.json')\n",
    "    kernelised_loco_cv_split_file = os.path.join(task_folder,f'{featurisation_method}_CBFV_rbf.json')\n",
    "    \n",
    "    data = pd.read_csv(data_file)\n",
    "    if tasks[task]['type'] == 'classification':\n",
    "        data['target'] = data['target'].astype(int)\n",
    "    with open(loco_cv_split_file) as f:\n",
    "        loco_cv_split = json.load(f)\n",
    "    with open(kernelised_loco_cv_split_file) as f:\n",
    "        kernelised_loco_cv_split = json.load(f)\n",
    "    \n",
    "    loco_cv_score = do_loco_cv(loco_cv_split, data, model, metric)\n",
    "    print(f'LOCO-CV score for {featurisation_method} is {round(loco_cv_score,3)}')\n",
    "    random_projection_loco_cv_score[featurisation_method] = loco_cv_score\n",
    "    \n",
    "    kernelised_loco_cv_score = do_loco_cv(kernelised_loco_cv_split, data, model, metric)\n",
    "    print(f'kernelised LOCO-CV score for {featurisation_method} is {round(kernelised_loco_cv_score,3)}')\n",
    "    random_projection_kernelised_loco_cv_score[featurisation_method] = kernelised_loco_cv_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3106415-dc90-4bad-9d70-699c7b63f182",
   "metadata": {},
   "source": [
    "## Lets see how much each featurisation method improves over a random projection of the same size\n",
    "negative numbers means it's worse than a random projection of the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee479787-b28a-433f-9990-b809bf543859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When measuring using an 80/20 train/test split magpie performs -34.759% better than an equally sized random projection\n",
      "When measuring using LOCO-CV magpie performs -34.759% better than an equally sized random projection\n",
      "When measuring using kernelised LOCO-CV magpie performs -0.041% better than an equally sized random projection\n",
      "\n",
      "When measuring using an 80/20 train/test split onehot performs -37.647% better than an equally sized random projection\n",
      "When measuring using LOCO-CV onehot performs -37.647% better than an equally sized random projection\n",
      "When measuring using kernelised LOCO-CV onehot performs 0.177% better than an equally sized random projection\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for featurisation_method in featurisations:\n",
    "    change = ((cbfv_train_test_score[featurisation_method]/random_projection_train_test_score[featurisation_method]) - 1) * 100\n",
    "    print(f'When measuring using an 80/20 train/test split {featurisation_method} performs {round(change,3)}% better than an equally sized random projection')\n",
    "    \n",
    "    change = ((cbfv_train_test_score[featurisation_method]/random_projection_train_test_score[featurisation_method]) - 1) * 100\n",
    "    print(f'When measuring using LOCO-CV {featurisation_method} performs {round(change,3)}% better than an equally sized random projection')\n",
    "    \n",
    "    change = ((cbfv_kernelised_loco_cv_score[featurisation_method]/random_projection_kernelised_loco_cv_score[featurisation_method]) - 1) * 100\n",
    "    print(f'When measuring using kernelised LOCO-CV {featurisation_method} performs {round(change,3)}% better than an equally sized random projection')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91484f32-3bf1-422b-9d58-bcac041bf573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
