{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2681deee-9e8e-4b2a-8efa-fc68bbb54f9b",
   "metadata": {},
   "source": [
    "# Analysing linear seperability of clusters\n",
    "This file takes you through an example of comparing the standard deviation in cluster size (cluster size uneveness) and the mean distance between a point in a cluster its centroid (spread of cluster) before and after application of radial basis function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdd922f-8f8c-424c-ae6d-4aa9e80b242a",
   "metadata": {},
   "source": [
    "## First some imports and setting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb2bb5a-2df4-4499-9685-fb07f7d874fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.kernel_approximation import RBFSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58293d2-22ca-4d47-84ca-6d0308cf92db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example on the glass formation ability dataset, using magpie featurisation\n",
    "# Feel free to select other files/folders to compare\n",
    "data_file = 'data/linear_seperability/datasets/gfa/magpie_CBFV.csv'\n",
    "# How many clusters do we want to investigate\n",
    "n_clusters = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43982586-a4d9-4b9b-99df-38f7b9fb052d",
   "metadata": {},
   "source": [
    "## Read in data and remove anything unneeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69216849-da42-4a12-b832-1b47e0010969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file)\n",
    "if 'target' in df.columns:\n",
    "    df = df.drop('target', axis=1)\n",
    "if 'formula' in df.columns:\n",
    "    df = df.drop('formula', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3ef0db-c511-4817-b041-4a6bcaf7a387",
   "metadata": {},
   "source": [
    "## Cluster and desired metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6f72d9d-b154-4da1-b17a-0c3dedb2ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=n_clusters)\n",
    "predictions = km.fit_predict(df)\n",
    "# Put it into a pandas Series for access to creature comforts\n",
    "predictions = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ad3326b-99e0-43a8-b800-6122a31b5766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2013\n",
       "6    1974\n",
       "4    1197\n",
       "1     585\n",
       "3     454\n",
       "2      52\n",
       "5      39\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Occupation of each cluster:\n",
    "predictions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10acba1a-ec07-4799-b7e9-df76fa0ba6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_size_uneveness = predictions.value_counts().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8739d545-1ce6-4dfd-952a-84e4c924ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spread of cluster\n",
    "total = 0\n",
    "for i, centroid in enumerate(km.cluster_centers_):\n",
    "    data_in_cluster = df[predictions==i]\n",
    "    total += cdist(data_in_cluster, centroid[None,:]).sum()\n",
    "spread_of_cluster = total/len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2feb77-5048-40c3-bb5f-40c50767582b",
   "metadata": {},
   "source": [
    "## Apply kernel function and repeat the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d4d8cba-632a-4edf-a923-88b0752f30ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf = RBFSampler()\n",
    "transformed_data = rbf.fit_transform(df)\n",
    "km = KMeans(n_clusters=n_clusters)\n",
    "predictions = km.fit_predict(transformed_data)\n",
    "# Put it into a pandas Series for access to creature comforts\n",
    "predictions = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a28b66b-df4f-4f02-abd2-8b9f42f09dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.34976240700686"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Occupation of each cluster:\n",
    "predictions.value_counts().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e11c13e-67fb-4d11-9855-a59b0a95edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelised_cluster_size_uneveness = predictions.value_counts().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c67e652d-7b34-4edf-b967-f56a1386ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spread of cluster\n",
    "total = 0\n",
    "for i, centroid in enumerate(km.cluster_centers_):\n",
    "    data_in_cluster = transformed_data[predictions==i]\n",
    "    total += cdist(data_in_cluster, centroid[None,:]).sum()\n",
    "kernelised_spread_of_cluster = total/len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76f7a6d-1be7-4eb1-aa0a-a6d2694f8af1",
   "metadata": {},
   "source": [
    "## Now lets compare the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ee5dd1d-b43f-406b-b68c-a9041d6dc527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying RBF changed the standard deviation in cluster sizes from 840.53 to 47.35, when clustering with k=7 on this dataset\n",
      "Applying RBF changed the mean distance from a point in a cluster to its centroid from 42250.87 to 0.98, when clustering with k=7 on this dataset\n"
     ]
    }
   ],
   "source": [
    "print(f'Applying RBF changed the standard deviation in cluster sizes from {round(cluster_size_uneveness,2)}\\\n",
    " to {round(kernelised_cluster_size_uneveness, 2)}, when clustering with k={n_clusters} on this dataset')\n",
    "print(f'Applying RBF changed the mean distance from a point in a cluster to its centroid from {round(spread_of_cluster,2)}\\\n",
    " to {round(kernelised_spread_of_cluster, 2)}, when clustering with k={n_clusters} on this dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5d463-44e6-4f3d-af52-2d4e333f3e48",
   "metadata": {},
   "source": [
    "As noted in the main text of the paper:\n",
    "\n",
    "* More even cluster sizes are not necessarily indicative of ***better*** (or worse) clusterings, more even clusters are helpful in LOCO-CV because highly uneven clusters increase the effect of size of the holdout set on the resulting measurement. \n",
    "* More tightly packed clusters are not necessarily indicative of ***better*** (or worse) clusterings they are an interesting side effect of the radial basis function transformation on these data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
